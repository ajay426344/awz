---
- name: Phase 1 - ESXi Patch Staging with Dynatrace Monitoring
  hosts: all
  gather_facts: no
  vars:
    ansible_user: root
    ansible_password: "Ajay@426344"
    ansible_connection: ssh
    ansible_ssh_common_args: '-o StrictHostKeyChecking=no'
    patch_file: "VMware-ESXi-8.0U3g-24859861-depot.zip"
    patch_profile: "ESXi-8.0U3g-24859861-standard"
    patch_source: "/mnt/patches"
    target_build: "24859861"
    dynatrace_url: "https://ofp39563.live.dynatrace.com"
    dynatrace_token: "dt0c01.MOQDVGYZV5NLQAAUFJMYVXM4.PNI42OD4D5V33H6IV4HQKJGB2VFDGJTPV3D6TKJBTMQ35JD62QIDNUM3OJKGQMVJ"
    # Upload timeout in seconds (120 minutes)
    patch_upload_timeout_seconds: 7200
    # Tuning for parallel upload: number of parts to split into for parallel scp
    parallel_splits: 4
    # scp extra options (no compression, use a light cipher). Adjust if your environment disallows cipher change.
    scp_extra_opts: "-o Compression=no -o Ciphers=aes128-ctr -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"

  tasks:
    - name: Set timestamps
      set_fact:
        current_epoch: "{{ now().strftime('%s') }}"
        current_iso: "{{ now().isoformat() }}"
      run_once: true

    - name: Record phase 1 start time
      set_fact:
        phase1_start_time: "{{ current_epoch }}"

    - name: Send Phase 1 start event to Dynatrace
      uri:
        url: "{{ dynatrace_url }}/api/v2/events/ingest"
        method: POST
        headers:
          Authorization: "Api-Token {{ dynatrace_token }}"
          Content-Type: "application/json"
        body_format: json
        body:
          eventType: "CUSTOM_INFO"
          title: "ESXi Phase 1 Staging Started"
          properties:
            host: "{{ inventory_hostname }}"
            phase: "phase1_staging"
            patch_file: "{{ patch_file }}"
            target_build: "{{ target_build }}"
            severity: "INFO"
        status_code: [200, 201, 202]
      delegate_to: localhost
      vars:
        ansible_connection: local

    - name: Check if patch needed
      set_fact:
        needs_patching: "{{ hostvars[inventory_hostname]['host_current_build']|default('0')|int < target_build|int }}"

    - name: Send eligibility metric to Dynatrace
      uri:
        url: "{{ dynatrace_url }}/api/v2/metrics/ingest"
        method: POST
        headers:
          Authorization: "Api-Token {{ dynatrace_token }}"
          Content-Type: "text/plain; charset=utf-8"
        body: |
          esxi.patch.phase1.eligibility,host={{ inventory_hostname }} {{ 1 if needs_patching else 0 }} {{ phase1_start_time }}
        status_code: [200, 201, 202, 204]
      delegate_to: localhost
      vars:
        ansible_connection: local

    - name: Execute staging process
      when: needs_patching
      block:

        - name: Create patches directory on ESXi
          raw: mkdir -p {{ hostvars[inventory_hostname]['host_selected_datastore']|default('/vmfs/volumes/datastore1') }}/patches

        - name: Check if patch file exists
          raw: ls -lh {{ hostvars[inventory_hostname]['host_selected_datastore']|default('/vmfs/volumes/datastore1') }}/patches/{{ patch_file }} 2>/dev/null || echo "NOT_FOUND"
          register: patch_exists

        - name: Record upload start time
          set_fact:
            upload_start: "{{ now().strftime('%s') }}"
          when: "'NOT_FOUND' in patch_exists.stdout"

        - name: Connectivity smoke-check: controller -> ESXi (BatchMode, no password prompt)
          delegate_to: localhost
          vars:
            ansible_connection: local
          shell: |
            ssh -o BatchMode=yes -o ConnectTimeout=10 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@{{ inventory_hostname }} 'echo SSH_OK'
          register: conn_check
          failed_when: conn_check.rc != 0
          changed_when: false
          when: "'NOT_FOUND' in patch_exists.stdout"

        - name: Split source file into parts on controller (only when missing)
          delegate_to: localhost
          vars:
            src_file: "{{ patch_source }}/{{ patch_file }}"
          shell: |
            set -euo pipefail
            TMPDIR="$(mktemp -d /tmp/patchsplit.XXXXXX)"
            echo "${TMPDIR}"
            # Prefer split -n if available (roughly equal pieces)
            if split --version >/dev/null 2>&1; then
              split -n r/{{ parallel_splits }} -d --additional-suffix=.part "{{ src_file }}" "${TMPDIR}/{{ patch_file }}.part."
            else
              FILESIZE=$(stat -c%s "{{ src_file }}")
              PARTSIZE=$(( (FILESIZE + {{ parallel_splits }} - 1) / {{ parallel_splits }} ))
              split -b ${PARTSIZE} -d --additional-suffix=.part "{{ src_file }}" "${TMPDIR}/{{ patch_file }}.part."
            fi
            # output tmpdir and list of parts
            echo "TMPDIR=${TMPDIR}"
            ls -1 "${TMPDIR}"/*.part.* || true
          register: split_out
          changed_when: true
          when: "'NOT_FOUND' in patch_exists.stdout"
          args:
            executable: /bin/bash

        - name: Set split_tmpdir and parts list facts
          set_fact:
            split_tmpdir: "{{ (split_out.stdout_lines[0] | default('')) if (split_out.stdout_lines is defined) else '' }}"
            split_parts: "{{ (split_out.stdout_lines[1:] | default([])) if (split_out.stdout_lines is defined) else [] }}"
          when: "'NOT_FOUND' in patch_exists.stdout"

        - name: Fallback - if split_parts empty, try extracting lines from split_out stdout
          set_fact:
            split_parts: "{{ split_out.stdout | regex_findall('(/tmp/patchsplit\\.[^\\s]+/[^\\s]+\\.part\\.[0-9]+)') }}"
          when:
            - "'NOT_FOUND' in patch_exists.stdout"
            - (split_parts | length) == 0

        - name: Launch parallel scp jobs (one async job per part)
          delegate_to: localhost
          vars:
            dest_ds: "{{ hostvars[inventory_hostname]['host_selected_datastore']|default('/vmfs/volumes/datastore1') }}/patches"
            dest_dir: "{{ dest_ds }}"
            scp_opts: "{{ scp_extra_opts }}"
          async: "{{ patch_upload_timeout_seconds }}"
          poll: 0
          loop: "{{ split_parts }}"
          loop_control:
            label: "{{ item | basename }}"
          shell: >
            scp {{ scp_opts }} "{{ item }}" "root@{{ inventory_hostname }}:{{ dest_dir }}/{{ patch_file }}.$(basename {{ item }})"
          register: scp_jobs
          when: "'NOT_FOUND' in patch_exists.stdout"
          args:
            executable: /bin/bash

        - name: Wait for each scp async job to finish (polling)
          delegate_to: localhost
          vars:
            wait_delay: 5
            wait_retries: "{{ (patch_upload_timeout_seconds // wait_delay) | int }}"
          block:
            - name: Build list of job ids
              set_fact:
                job_list: "{{ scp_jobs.results | map(attribute='ansible_job_id') | list }}"
              when: scp_jobs is defined

            - name: Poll each async job until finished
              async_status:
                jid: "{{ item }}"
              register: job_status
              until: job_status.finished
              retries: "{{ wait_retries }}"
              delay: "{{ wait_delay }}"
              loop: "{{ job_list | default([]) }}"
              loop_control:
                label: "{{ item }}"
              when: job_list is defined
          when: "'NOT_FOUND' in patch_exists.stdout"

        - name: Collect job statuses and determine upload rc
          set_fact:
            upload_failed_jobs: >-
              {{
                (
                  job_status.results | default([])
                  | selectattr('ansible_facts.ansible_job_id','defined')
                  | map(attribute='ansible_facts')
                  | selectattr('rc','defined')
                  | selectattr('rc','ne',0)
                  | list
                )
              }}
          when:
            - "'NOT_FOUND' in patch_exists.stdout"
            - job_status is defined

        - name: Concatenate parts on ESXi and cleanup remote parts (only if no failed upload jobs)
          delegate_to: localhost
          vars:
            dest_ds: "{{ hostvars[inventory_hostname]['host_selected_datastore']|default('/vmfs/volumes/datastore1') }}/patches"
          shell: |
            set -euo pipefail
            # remote concat and cleanup
            ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@{{ inventory_hostname }} bash -lc $'cat "{{ dest_ds }}/{{ patch_file }}.part."* > "{{ dest_ds }}/{{ patch_file }}" && rm -f "{{ dest_ds }}/{{ patch_file }}.part."*'
          register: concat_result
          changed_when: concat_result.rc == 0
          failed_when: concat_result.rc != 0
          when:
            - "'NOT_FOUND' in patch_exists.stdout"
            - upload_failed_jobs is defined
            - (upload_failed_jobs | length) == 0

        - name: Set rsync_result fact on success (rc 0)
          set_fact:
            rsync_result:
              rc: 0
              stdout: "{{ concat_result.stdout | default('') }}"
              stderr: "{{ concat_result.stderr | default('') }}"
          when:
            - "'NOT_FOUND' in patch_exists.stdout"
            - concat_result is defined
            - concat_result.rc == 0

        - name: Set rsync_result fact on upload failure (one or more failed jobs)
          set_fact:
            rsync_result:
              rc: 2
              stdout: "{{ (job_status.results | map(attribute='stdout') | join('\\n')) | default('') }}"
              stderr: "{{ (job_status.results | map(attribute='stderr') | join('\\n')) | default('') }}"
          when:
            - "'NOT_FOUND' in patch_exists.stdout"
            - upload_failed_jobs is defined
            - (upload_failed_jobs | length) > 0

        - name: If concat failed but uploads looked ok, set rsync_result from concat
          set_fact:
            rsync_result:
              rc: "{{ concat_result.rc | default(1) }}"
              stdout: "{{ concat_result.stdout | default('') }}"
              stderr: "{{ concat_result.stderr | default('') }}"
          when:
            - "'NOT_FOUND' in patch_exists.stdout"
            - upload_failed_jobs is defined
            - (upload_failed_jobs | length) == 0
            - concat_result is defined
            - concat_result.rc != 0

        - name: Send Dynatrace metric if upload timed out (detected by rc 124)
          when:
            - "'NOT_FOUND' in patch_exists.stdout"
            - rsync_result is defined
            - rsync_result.rc == 124
          uri:
            url: "{{ dynatrace_url }}/api/v2/metrics/ingest"
            method: POST
            headers:
              Authorization: "Api-Token {{ dynatrace_token }}"
              Content-Type: "text/plain; charset=utf-8"
            body: |
              esxi.patch.phase1.upload_timeout,host={{ inventory_hostname }} 1 {{ now().strftime('%s') }}
            status_code: [200, 201, 202, 204]
          delegate_to: localhost
          vars:
            ansible_connection: local

        - name: Send Dynatrace event and metric if upload failed for any other reason
          when:
            - "'NOT_FOUND' in patch_exists.stdout"
            - rsync_result is defined
            - rsync_result.rc != 0
          block:
            - name: Send upload failure metric
              uri:
                url: "{{ dynatrace_url }}/api/v2/metrics/ingest"
                method: POST
                headers:
                  Authorization: "Api-Token {{ dynatrace_token }}"
                  Content-Type: "text/plain; charset=utf-8"
                body: |
                  esxi.patch.phase1.upload_success,host={{ inventory_hostname }} 0 {{ now().strftime('%s') }}
                status_code: [200, 201, 202, 204]
              delegate_to: localhost
              vars:
                ansible_connection: local

            - name: Send upload failure event with reason to Dynatrace
              uri:
                url: "{{ dynatrace_url }}/api/v2/events/ingest"
                method: POST
                headers:
                  Authorization: "Api-Token {{ dynatrace_token }}"
                  Content-Type: "application/json"
                body_format: json
                body:
                  eventType: "CUSTOM_ALERT"
                  title: "ESXi Phase 1 Upload Failed"
                  properties:
                    host: "{{ inventory_hostname }}"
                    phase: "phase1_staging"
                    patch_file: "{{ patch_file }}"
                    rc: "{{ rsync_result.rc }}"
                    stderr: "{{ rsync_result.stderr | default('') }}"
                    stdout: "{{ rsync_result.stdout | default('') }}"
                    severity: "ERROR"
                status_code: [200, 201, 202]
              delegate_to: localhost
              vars:
                ansible_connection: local

        - name: Calculate upload duration and send to Dynatrace
          when:
            - "'NOT_FOUND' in patch_exists.stdout"
            - rsync_result is defined
            - rsync_result.rc == 0
          block:
            - set_fact:
                upload_duration: "{{ (now().strftime('%s') | int) - (upload_start | int) }}"
            - uri:
                url: "{{ dynatrace_url }}/api/v2/metrics/ingest"
                method: POST
                headers:
                  Authorization: "Api-Token {{ dynatrace_token }}"
                  Content-Type: "text/plain; charset=utf-8"
                body: |
                  esxi.patch.phase1.upload_duration_seconds,host={{ inventory_hostname }} {{ upload_duration }} {{ now().strftime('%s') }}
                status_code: [200, 201, 202, 204]
              delegate_to: localhost
              vars:
                ansible_connection: local

        - name: Perform dry-run
          raw: |
            esxcli software profile update \
              -d {{ hostvars[inventory_hostname]['host_selected_datastore']|default('/vmfs/volumes/datastore1') }}/patches/{{ patch_file }} \
              -p {{ patch_profile }} \
              --dry-run
          register: dry_run_result

        - name: Send dry-run status to Dynatrace
          uri:
            url: "{{ dynatrace_url }}/api/v2/metrics/ingest"
            method: POST
            headers:
              Authorization: "Api-Token {{ dynatrace_token }}"
              Content-Type: "text/plain; charset=utf-8"
            body: |
              esxi.patch.phase1.dryrun_status,host={{ inventory_hostname }} {{ 1 if dry_run_result.rc == 0 else 0 }} {{ now().strftime('%s') }}
            status_code: [200, 201, 202, 204]
          delegate_to: localhost
          vars:
            ansible_connection: local

        - name: Stage patch with no-live-install
          raw: |
            esxcli software profile update \
              -d {{ hostvars[inventory_hostname]['host_selected_datastore']|default('/vmfs/volumes/datastore1') }}/patches/{{ patch_file }} \
              -p {{ patch_profile }} \
              --no-live-install
          register: staging_result

        - name: Validate staging success
          set_fact:
            staging_success: "{{ 'The update completed successfully' in staging_result.stdout }}"
            reboot_required: "{{ 'Reboot Required: true' in staging_result.stdout }}"
            phase1_duration: "{{ (now().strftime('%s') | int) - (phase1_start_time | int) }}"

        - name: Send Phase 1 completion metrics to Dynatrace
          uri:
            url: "{{ dynatrace_url }}/api/v2/metrics/ingest"
            method: POST
            headers:
              Authorization: "Api-Token {{ dynatrace_token }}"
              Content-Type: "text/plain; charset=utf-8"
            body: |
              esxi.patch.phase1.staging_status,host={{ inventory_hostname }} {{ 1 if staging_success else 0 }} {{ now().strftime('%s') }}
              esxi.patch.phase1.reboot_required,host={{ inventory_hostname }} {{ 1 if reboot_required else 0 }} {{ now().strftime('%s') }}
              esxi.patch.phase1.duration_seconds,host={{ inventory_hostname }} {{ phase1_duration }} {{ now().strftime('%s') }}
            status_code: [200, 201, 202, 204]
          delegate_to: localhost
          vars:
            ansible_connection: local

        - name: Send Phase 1 completion event to Dynatrace
          uri:
            url: "{{ dynatrace_url }}/api/v2/events/ingest"
            method: POST
            headers:
              Authorization: "Api-Token {{ dynatrace_token }}"
              Content-Type: "application/json"
            body_format: json
            body:
              eventType: "CUSTOM_INFO"
              title: "ESXi Phase 1 {{ 'Completed' if staging_success else 'Failed' }}"
              properties:
                host: "{{ inventory_hostname }}"
                phase: "phase1_staging"
                status: "{{ 'success' if staging_success else 'failed' }}"
                duration_seconds: "{{ phase1_duration }}"
                reboot_required: "{{ reboot_required }}"
                severity: "{{ 'INFO' if staging_success else 'ERROR' }}"
            status_code: [200, 201, 202]
          delegate_to: localhost
          vars:
            ansible_connection: local

    - name: Send skip notification if patch not needed
      uri:
        url: "{{ dynatrace_url }}/api/v2/events/ingest"
        method: POST
        headers:
          Authorization: "Api-Token {{ dynatrace_token }}"
          Content-Type: "application/json"
        body_format: json
        body:
          eventType: "CUSTOM_INFO"
          title: "ESXi Phase 1 Skipped - Already Updated"
          properties:
            host: "{{ inventory_hostname }}"
            phase: "phase1_staging"
            status: "skipped"
            current_build: "{{ hostvars[inventory_hostname]['host_current_build']|default('unknown') }}"
            target_build: "{{ target_build }}"
            severity: "INFO"
        status_code: [200, 201, 202]
      delegate_to: localhost
      vars:
        ansible_connection: local
      when: not needs_patching
